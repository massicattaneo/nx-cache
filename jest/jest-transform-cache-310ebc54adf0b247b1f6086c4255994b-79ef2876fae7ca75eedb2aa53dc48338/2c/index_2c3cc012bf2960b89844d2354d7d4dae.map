{"version":3,"sources":["/Users/mcattaneo/workspace/frontend/node_modules/micromark-util-subtokenize/index.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Token} Token\n */\n\nimport {splice} from 'micromark-util-chunked'\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} events\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */ // eslint-disable-next-line complexity\nexport function subtokenize(events) {\n  /** @type {Record<string, number>} */\n  const jumps = {}\n  let index = -1\n  /** @type {Event} */\n  let event\n  /** @type {number | undefined} */\n  let lineIndex\n  /** @type {number} */\n  let otherIndex\n  /** @type {Event} */\n  let otherEvent\n  /** @type {Array<Event>} */\n  let parameters\n  /** @type {Array<Event>} */\n  let subevents\n  /** @type {boolean | undefined} */\n  let more\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n    event = events[index]\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (\n      index &&\n      event[1].type === 'chunkFlow' &&\n      events[index - 1][1].type === 'listItemPrefix'\n    ) {\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'lineEndingBlank'\n      ) {\n        otherIndex += 2\n      }\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'content'\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break\n          }\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index\n      lineIndex = undefined\n      while (otherIndex--) {\n        otherEvent = events[otherIndex]\n        if (\n          otherEvent[1].type === 'lineEnding' ||\n          otherEvent[1].type === 'lineEndingBlank'\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank'\n            }\n            otherEvent[1].type = 'lineEnding'\n            lineIndex = otherIndex\n          }\n        } else {\n          break\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = Object.assign({}, events[lineIndex][1].start)\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        splice(events, lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n  return !more\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {Array<Event>} events\n * @param {number} eventIndex\n * @returns {Record<string, number>}\n */\nfunction subcontent(events, eventIndex) {\n  const token = events[eventIndex][1]\n  const context = events[eventIndex][2]\n  let startPosition = eventIndex - 1\n  /** @type {Array<number>} */\n  const startPositions = []\n  const tokenizer =\n    token._tokenizer || context.parser[token.contentType](token.start)\n  const childEvents = tokenizer.events\n  /** @type {Array<[number, number]>} */\n  const jumps = []\n  /** @type {Record<string, number>} */\n  const gaps = {}\n  /** @type {Array<Chunk>} */\n  let stream\n  /** @type {Token | undefined} */\n  let previous\n  let index = -1\n  /** @type {Token | undefined} */\n  let current = token\n  let adjust = 0\n  let start = 0\n  const breaks = [start]\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition)\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current)\n      if (!current.next) {\n        stream.push(null)\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start)\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n      tokenizer.write(stream)\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    }\n\n    // Unravel the next token.\n    previous = current\n    current = current.next\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token\n  while (++index < childEvents.length) {\n    if (\n      // Find a void token that includes a break.\n      childEvents[index][0] === 'exit' &&\n      childEvents[index - 1][0] === 'enter' &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      start = index + 1\n      breaks.push(start)\n      // Help GC.\n      current._tokenizer = undefined\n      current.previous = undefined\n      current = current.next\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = []\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined\n    current.previous = undefined\n  } else {\n    breaks.pop()\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1])\n    const start = startPositions.pop()\n    jumps.unshift([start, start + slice.length - 1])\n    splice(events, start, 2, slice)\n  }\n  index = -1\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n  return gaps\n}\n"],"names":["subtokenize","events","jumps","index","event","lineIndex","otherIndex","otherEvent","parameters","subevents","more","length","type","_tokenizer","_isInFirstContentOfListItem","contentType","Object","assign","subcontent","_container","undefined","end","start","slice","unshift","splice","eventIndex","token","context","startPosition","startPositions","tokenizer","parser","childEvents","gaps","stream","previous","current","adjust","breaks","push","sliceStream","next","defineSkip","_gfmTasklistFirstContentOfListItem","write","line","pop"],"rangeMappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;","mappings":"AAAA;;;;CAIC;;;;+BAWeA;;;eAAAA;;;sCATK;AASd,SAASA,YAAYC,MAAM;IAChC,mCAAmC,GACnC,MAAMC,QAAQ,CAAC;IACf,IAAIC,QAAQ,CAAC;IACb,kBAAkB,GAClB,IAAIC;IACJ,+BAA+B,GAC/B,IAAIC;IACJ,mBAAmB,GACnB,IAAIC;IACJ,kBAAkB,GAClB,IAAIC;IACJ,yBAAyB,GACzB,IAAIC;IACJ,yBAAyB,GACzB,IAAIC;IACJ,gCAAgC,GAChC,IAAIC;IACJ,MAAO,EAAEP,QAAQF,OAAOU,MAAM,CAAE;QAC9B,MAAOR,SAASD,MAAO;YACrBC,QAAQD,KAAK,CAACC,MAAM;QACtB;QACAC,QAAQH,MAAM,CAACE,MAAM;QAErB,yEAAyE;QACzE,0CAA0C;QAC1C,IACEA,SACAC,KAAK,CAAC,EAAE,CAACQ,IAAI,KAAK,eAClBX,MAAM,CAACE,QAAQ,EAAE,CAAC,EAAE,CAACS,IAAI,KAAK,kBAC9B;YACAH,YAAYL,KAAK,CAAC,EAAE,CAACS,UAAU,CAACZ,MAAM;YACtCK,aAAa;YACb,IACEA,aAAaG,UAAUE,MAAM,IAC7BF,SAAS,CAACH,WAAW,CAAC,EAAE,CAACM,IAAI,KAAK,mBAClC;gBACAN,cAAc;YAChB;YACA,IACEA,aAAaG,UAAUE,MAAM,IAC7BF,SAAS,CAACH,WAAW,CAAC,EAAE,CAACM,IAAI,KAAK,WAClC;gBACA,MAAO,EAAEN,aAAaG,UAAUE,MAAM,CAAE;oBACtC,IAAIF,SAAS,CAACH,WAAW,CAAC,EAAE,CAACM,IAAI,KAAK,WAAW;wBAC/C;oBACF;oBACA,IAAIH,SAAS,CAACH,WAAW,CAAC,EAAE,CAACM,IAAI,KAAK,aAAa;wBACjDH,SAAS,CAACH,WAAW,CAAC,EAAE,CAACQ,2BAA2B,GAAG;wBACvDR;oBACF;gBACF;YACF;QACF;QAEA,SAAS;QACT,IAAIF,KAAK,CAAC,EAAE,KAAK,SAAS;YACxB,IAAIA,KAAK,CAAC,EAAE,CAACW,WAAW,EAAE;gBACxBC,OAAOC,MAAM,CAACf,OAAOgB,WAAWjB,QAAQE;gBACxCA,QAAQD,KAAK,CAACC,MAAM;gBACpBO,OAAO;YACT;QACF,OAEK,IAAIN,KAAK,CAAC,EAAE,CAACe,UAAU,EAAE;YAC5Bb,aAAaH;YACbE,YAAYe;YACZ,MAAOd,aAAc;gBACnBC,aAAaN,MAAM,CAACK,WAAW;gBAC/B,IACEC,UAAU,CAAC,EAAE,CAACK,IAAI,KAAK,gBACvBL,UAAU,CAAC,EAAE,CAACK,IAAI,KAAK,mBACvB;oBACA,IAAIL,UAAU,CAAC,EAAE,KAAK,SAAS;wBAC7B,IAAIF,WAAW;4BACbJ,MAAM,CAACI,UAAU,CAAC,EAAE,CAACO,IAAI,GAAG;wBAC9B;wBACAL,UAAU,CAAC,EAAE,CAACK,IAAI,GAAG;wBACrBP,YAAYC;oBACd;gBACF,OAAO;oBACL;gBACF;YACF;YACA,IAAID,WAAW;gBACb,gBAAgB;gBAChBD,KAAK,CAAC,EAAE,CAACiB,GAAG,GAAGL,OAAOC,MAAM,CAAC,CAAC,GAAGhB,MAAM,CAACI,UAAU,CAAC,EAAE,CAACiB,KAAK;gBAE3D,yCAAyC;gBACzCd,aAAaP,OAAOsB,KAAK,CAAClB,WAAWF;gBACrCK,WAAWgB,OAAO,CAACpB;gBACnBqB,IAAAA,4BAAM,EAACxB,QAAQI,WAAWF,QAAQE,YAAY,GAAGG;YACnD;QACF;IACF;IACA,OAAO,CAACE;AACV;AAEA;;;;;;CAMC,GACD,SAASQ,WAAWjB,MAAM,EAAEyB,UAAU;IACpC,MAAMC,QAAQ1B,MAAM,CAACyB,WAAW,CAAC,EAAE;IACnC,MAAME,UAAU3B,MAAM,CAACyB,WAAW,CAAC,EAAE;IACrC,IAAIG,gBAAgBH,aAAa;IACjC,0BAA0B,GAC1B,MAAMI,iBAAiB,EAAE;IACzB,MAAMC,YACJJ,MAAMd,UAAU,IAAIe,QAAQI,MAAM,CAACL,MAAMZ,WAAW,CAAC,CAACY,MAAML,KAAK;IACnE,MAAMW,cAAcF,UAAU9B,MAAM;IACpC,oCAAoC,GACpC,MAAMC,QAAQ,EAAE;IAChB,mCAAmC,GACnC,MAAMgC,OAAO,CAAC;IACd,yBAAyB,GACzB,IAAIC;IACJ,8BAA8B,GAC9B,IAAIC;IACJ,IAAIjC,QAAQ,CAAC;IACb,8BAA8B,GAC9B,IAAIkC,UAAUV;IACd,IAAIW,SAAS;IACb,IAAIhB,QAAQ;IACZ,MAAMiB,SAAS;QAACjB;KAAM;IAEtB,sEAAsE;IACtE,gBAAgB;IAChB,MAAOe,QAAS;QACd,iDAAiD;QACjD,MAAOpC,MAAM,CAAC,EAAE4B,cAAc,CAAC,EAAE,KAAKQ,QAAS;QAC7C,SAAS;QACX;QACAP,eAAeU,IAAI,CAACX;QACpB,IAAI,CAACQ,QAAQxB,UAAU,EAAE;YACvBsB,SAASP,QAAQa,WAAW,CAACJ;YAC7B,IAAI,CAACA,QAAQK,IAAI,EAAE;gBACjBP,OAAOK,IAAI,CAAC;YACd;YACA,IAAIJ,UAAU;gBACZL,UAAUY,UAAU,CAACN,QAAQf,KAAK;YACpC;YACA,IAAIe,QAAQvB,2BAA2B,EAAE;gBACvCiB,UAAUa,kCAAkC,GAAG;YACjD;YACAb,UAAUc,KAAK,CAACV;YAChB,IAAIE,QAAQvB,2BAA2B,EAAE;gBACvCiB,UAAUa,kCAAkC,GAAGxB;YACjD;QACF;QAEA,0BAA0B;QAC1BgB,WAAWC;QACXA,UAAUA,QAAQK,IAAI;IACxB;IAEA,6EAA6E;IAC7E,sBAAsB;IACtBL,UAAUV;IACV,MAAO,EAAExB,QAAQ8B,YAAYtB,MAAM,CAAE;QACnC,IACE,2CAA2C;QAC3CsB,WAAW,CAAC9B,MAAM,CAAC,EAAE,KAAK,UAC1B8B,WAAW,CAAC9B,QAAQ,EAAE,CAAC,EAAE,KAAK,WAC9B8B,WAAW,CAAC9B,MAAM,CAAC,EAAE,CAACS,IAAI,KAAKqB,WAAW,CAAC9B,QAAQ,EAAE,CAAC,EAAE,CAACS,IAAI,IAC7DqB,WAAW,CAAC9B,MAAM,CAAC,EAAE,CAACmB,KAAK,CAACwB,IAAI,KAAKb,WAAW,CAAC9B,MAAM,CAAC,EAAE,CAACkB,GAAG,CAACyB,IAAI,EACnE;YACAxB,QAAQnB,QAAQ;YAChBoC,OAAOC,IAAI,CAAClB;YACZ,WAAW;YACXe,QAAQxB,UAAU,GAAGO;YACrBiB,QAAQD,QAAQ,GAAGhB;YACnBiB,UAAUA,QAAQK,IAAI;QACxB;IACF;IAEA,WAAW;IACXX,UAAU9B,MAAM,GAAG,EAAE;IAErB,yEAAyE;IACzE,2DAA2D;IAC3D,sEAAsE;IACtE,IAAIoC,SAAS;QACX,WAAW;QACXA,QAAQxB,UAAU,GAAGO;QACrBiB,QAAQD,QAAQ,GAAGhB;IACrB,OAAO;QACLmB,OAAOQ,GAAG;IACZ;IAEA,uEAAuE;IACvE,+DAA+D;IAC/D5C,QAAQoC,OAAO5B,MAAM;IACrB,MAAOR,QAAS;QACd,MAAMoB,QAAQU,YAAYV,KAAK,CAACgB,MAAM,CAACpC,MAAM,EAAEoC,MAAM,CAACpC,QAAQ,EAAE;QAChE,MAAMmB,QAAQQ,eAAeiB,GAAG;QAChC7C,MAAMsB,OAAO,CAAC;YAACF;YAAOA,QAAQC,MAAMZ,MAAM,GAAG;SAAE;QAC/Cc,IAAAA,4BAAM,EAACxB,QAAQqB,OAAO,GAAGC;IAC3B;IACApB,QAAQ,CAAC;IACT,MAAO,EAAEA,QAAQD,MAAMS,MAAM,CAAE;QAC7BuB,IAAI,CAACI,SAASpC,KAAK,CAACC,MAAM,CAAC,EAAE,CAAC,GAAGmC,SAASpC,KAAK,CAACC,MAAM,CAAC,EAAE;QACzDmC,UAAUpC,KAAK,CAACC,MAAM,CAAC,EAAE,GAAGD,KAAK,CAACC,MAAM,CAAC,EAAE,GAAG;IAChD;IACA,OAAO+B;AACT"}